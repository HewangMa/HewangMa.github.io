{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base_path is /mnt/mechanical/projects/engineering_practice/local !!\n"
     ]
    }
   ],
   "source": [
    "# import and set default\n",
    "import os\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "base_path = os.getcwd()\n",
    "print(f\"Base_path is {base_path} !!\")\n",
    "sys.path.append(os.path.join(base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are on device cuda !!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "time_step = 8\n",
    "num_class = 64\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"We are on device {device} !!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0             1             2             3             4  \\\n",
      "count  2.501450e+05  2.501450e+05  2.501450e+05  2.501450e+05  2.501450e+05   \n",
      "mean  -8.980599e-16  6.249152e-17 -4.072174e-16  7.544430e-17 -2.599647e-16   \n",
      "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
      "min   -3.172120e+00 -7.282713e+00 -4.634124e+00 -6.873010e+00 -4.220964e+00   \n",
      "25%   -6.637011e-01 -4.439173e-01 -5.904385e-01 -5.189889e-01 -6.259770e-01   \n",
      "50%   -1.006514e-01  1.222280e-01 -2.775436e-03  9.519070e-02 -3.401265e-02   \n",
      "75%    5.159171e-01  6.162396e-01  5.382176e-01  6.487910e-01  5.541272e-01   \n",
      "max    7.671914e+00  3.586334e+00  5.774233e+00  3.485932e+00  7.329959e+00   \n",
      "\n",
      "                  5             6             7             8             9  \\\n",
      "count  2.501450e+05  2.501450e+05  2.501450e+05  2.501450e+05  2.501450e+05   \n",
      "mean   4.817528e-17  7.817121e-17 -1.408900e-16  6.362773e-18 -8.180708e-18   \n",
      "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
      "min   -5.843409e+00 -4.248132e+00 -4.469729e+00 -5.482741e+00 -5.539742e+00   \n",
      "25%   -5.500147e-01 -6.585590e-01 -6.754890e-01 -6.792196e-01 -6.104768e-01   \n",
      "50%    1.510659e-01 -2.323773e-02  1.400156e-01  2.587240e-02  8.996345e-02   \n",
      "75%    7.017422e-01  6.011975e-01  7.108807e-01  7.096089e-01  6.999644e-01   \n",
      "max    3.282191e+00  5.072870e+00  4.656055e+00  3.337499e+00  3.939433e+00   \n",
      "\n",
      "       ...            31            32            33            34  \\\n",
      "count  ...  2.501450e+05  2.501450e+05  2.501450e+05  2.501450e+05   \n",
      "mean   ...  4.408492e-17 -8.180708e-18 -6.090082e-17  1.272555e-17   \n",
      "std    ...  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
      "min    ... -4.511662e+00 -6.257430e+00 -4.061580e+00 -4.620737e+00   \n",
      "25%    ... -6.592131e-01 -6.630135e-01 -7.003821e-01 -6.513029e-01   \n",
      "50%    ... -1.039845e-01 -3.986493e-02 -5.996493e-02 -4.490318e-02   \n",
      "75%    ...  5.432487e-01  6.008349e-01  6.109580e-01  6.119657e-01   \n",
      "max    ...  6.819522e+00  5.498557e+00  5.817202e+00  5.409336e+00   \n",
      "\n",
      "                 35            36            37            38            39  \\\n",
      "count  2.501450e+05  2.501450e+05  2.501450e+05  2.501450e+05  2.501450e+05   \n",
      "mean   2.204246e-17 -6.090082e-17  3.272283e-17  1.095306e-16  8.180708e-18   \n",
      "std    1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00  1.000002e+00   \n",
      "min   -4.958278e+00 -4.661846e+00 -7.138073e+00 -7.862654e+00 -5.691512e+00   \n",
      "25%   -6.647849e-01 -6.464551e-01 -6.451144e-01 -6.309939e-01 -6.628728e-01   \n",
      "50%    2.100152e-02 -1.445284e-02 -9.928965e-03 -1.519771e-03  2.107375e-03   \n",
      "75%    6.378179e-01  6.229124e-01  6.105097e-01  6.040879e-01  6.260539e-01   \n",
      "max    4.680396e+00  4.970828e+00  5.132728e+00  7.195963e+00  6.477545e+00   \n",
      "\n",
      "                  40  \n",
      "count  250145.000000  \n",
      "mean       32.482468  \n",
      "std        18.484404  \n",
      "min         1.000000  \n",
      "25%        16.000000  \n",
      "50%        32.000000  \n",
      "75%        49.000000  \n",
      "max        64.000000  \n",
      "\n",
      "[8 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"./data/data.csv\")\n",
    "df = df[df.iloc[:, -1].between(1, num_class)]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "df = pd.concat([X, y], axis=1)\n",
    "print(df.describe())\n",
    "\n",
    "# 保存均值和标准差\n",
    "mean = scaler.mean_\n",
    "scale = scaler.scale_\n",
    "\n",
    "# 保存均值和标准差到文件\n",
    "np.save(\"data/mean.npy\", mean)\n",
    "np.save(\"data/scale.npy\", scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We got totally 31264 for 64 persons\n",
      "31264\n",
      "X shape: (31264, 8, 40), y shape: (31264, 1)\n",
      "Train np shape: (15318, 8, 40), (15318, 1)\n",
      "        Val np shape: (6566, 8, 40), (6566, 1)\n",
      "        Test np shape: (9380, 8, 40), (9380, 1)\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "grouped_data = []\n",
    "\n",
    "\n",
    "for label in range(1, num_class + 1):\n",
    "    person = df[df.iloc[:, -1] == label]\n",
    "    i = 0\n",
    "    while True:\n",
    "        if i + time_step > len(person):\n",
    "            break\n",
    "        sample = person[i : i + time_step]\n",
    "        i += time_step\n",
    "        grouped_data.append(sample)\n",
    "\n",
    "print(f\"We got totally {len(grouped_data)} for {num_class} persons\")\n",
    "print(len(grouped_data))\n",
    "\n",
    "X = [sample.iloc[:, :-1].values for sample in grouped_data]\n",
    "labels = []\n",
    "for sample in grouped_data:\n",
    "    ll = sample.iloc[:, -1].values\n",
    "    labels.append([ll[0]])\n",
    "X = np.array(X)\n",
    "y = np.array(labels)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=42\n",
    ")\n",
    "print(\n",
    "    f\"\"\"Train np shape: {X_train.shape}, {y_train.shape}\n",
    "        Val np shape: {X_val.shape}, {y_val.shape}\n",
    "        Test np shape: {X_test.shape}, {y_test.shape}\n",
    "      \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader shape: 240\n",
      "        Val loader shape: 103\n",
      "        Test loader shape: 147\n",
      "      \n",
      "2 64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "X_val_tensor = torch.Tensor(X_val)\n",
    "y_val_tensor = torch.Tensor(y_val)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\n",
    "    f\"\"\"Train loader shape: {len(train_loader)}\n",
    "        Val loader shape: {len(val_loader)}\n",
    "        Test loader shape: {len(test_loader)}\n",
    "      \"\"\"\n",
    ")\n",
    "\n",
    "for one in train_loader:\n",
    "    print(len(one), len(one[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model and Train example to valid data shape\n",
      "torch.Size([64, 8, 40])\n",
      "Output shape: torch.Size([64, 1])\n",
      "here we know that data shape is ok\n"
     ]
    }
   ],
   "source": [
    "# Build model and Train example\n",
    "\n",
    "from models.models import LSTMModel\n",
    "\n",
    "print(\"Build model and Train example to valid data shape\")\n",
    "# Define model parameters\n",
    "input_size = 40\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the model\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Generate sample input data\n",
    "input_data = torch.randn(batch_size, time_step, input_size).to(device)\n",
    "print(input_data.shape)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_data)\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "print(\"here we know that data shape is ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model of 200\n",
      "saved model of 400\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Actually Train\n",
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 400\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.float().to(device), labels.float().to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1 + 600) in [800, 1000]:\n",
    "        torch.save(\n",
    "            model,\n",
    "            os.path.join(\n",
    "                base_path, \"models\", f\"final_e{epoch+1+600}_full_model_for_64.pth\"\n",
    "            ),\n",
    "        )\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            os.path.join(\n",
    "                base_path, \"models\", f\"final_e{epoch+1+600}_model_weights_for_64.pth\"\n",
    "            ),\n",
    "        )\n",
    "        print(f\"saved model of {epoch+1}\")\n",
    "\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for e = 2 : acc = 0.017057569296375266, f1 = 0.0005241090146750524\n",
      "for e = 4 : acc = 0.016367741126301266, f1 = 0.0005032547664589375\n",
      "for e = 6 : acc = 0.08064718424683306, f1 = 0.06621835272369642\n",
      "for e = 8 : acc = 0.13188260378778377, f1 = 0.11775124206390358\n",
      "for e = 10 : acc = 0.21183995986454282, f1 = 0.2015388615678037\n",
      "for e = 20 : acc = 0.5082779380408879, f1 = 0.4962581243949295\n",
      "for e = 30 : acc = 0.675216355198796, f1 = 0.6590987806516768\n",
      "for e = 40 : acc = 0.55863539445629, f1 = 0.554207148790254\n",
      "for e = 80 : acc = 0.6777248212717923, f1 = 0.6767027345538582\n",
      "for e = 120 : acc = 0.9436222250094067, f1 = 0.9435270586467183\n",
      "for e = 160 : acc = 0.940674777373636, f1 = 0.9404597079865855\n",
      "for e = 200 : acc = 0.9655085914963, f1 = 0.9654915471126182\n",
      "for e = 400 : acc = 0.9705255236422927, f1 = 0.9704617094640144\n",
      "for e = 600 : acc = 0.953154396086793, f1 = 0.952819959626162\n",
      "for e = 800 : acc = 0.9798068481123793, f1 = 0.9796734488076233\n",
      "for e = 1000 : acc = 0.97585601404741, f1 = 0.9758147117261818\n"
     ]
    }
   ],
   "source": [
    "# predict with torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "for e in [2, 4, 6, 8, 10, 20, 30, 40, 80, 120, 160, 200, 400, 600, 800, 1000]:\n",
    "    all_y_true = np.zeros((0, 1))\n",
    "    all_y_pred = np.zeros((0, 1))\n",
    "    model_full = torch.load(f\"models/final_e{e}_full_model_for_64.pth\")\n",
    "    # model.load_state_dict(torch.load(f\"models/final_e{e}_model_weights_for_64.pth\"))\n",
    "    for inputs, y_true in val_loader:\n",
    "        inputs, y_true = inputs.to(device), y_true.to(device)\n",
    "        y_pred = model_full(inputs)\n",
    "\n",
    "        y_pred = np.round(y_pred.to(\"cpu\").detach().numpy())\n",
    "        y_true = np.round(y_true.to(\"cpu\").detach().numpy())\n",
    "        all_y_true = np.concatenate([all_y_true, y_true])\n",
    "        all_y_pred = np.concatenate([all_y_pred, y_pred])\n",
    "\n",
    "    for inputs, y_true in test_loader:\n",
    "        inputs, y_true = inputs.to(device), y_true.to(device)\n",
    "        y_pred = model_full(inputs)\n",
    "\n",
    "        y_pred = np.round(y_pred.to(\"cpu\").detach().numpy())\n",
    "        y_true = np.round(y_true.to(\"cpu\").detach().numpy())\n",
    "        all_y_true = np.concatenate([all_y_true, y_true])\n",
    "        all_y_pred = np.concatenate([all_y_pred, y_pred])\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "\n",
    "    # 计算 F1 分数\n",
    "    f1 = f1_score(all_y_true, all_y_pred, average=\"macro\")\n",
    "    print(f\"for e = {e} : acc = {accuracy}, f1 = {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 93761\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Total Parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(64, 8, 40, strides=[320, 40, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(1, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::LSTM_321 : Float(1, 256, 40, strides=[10240, 40, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_322 : Float(1, 256, 64, strides=[16384, 64, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_323 : Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_345 : Float(1, 256, 64, strides=[16384, 64, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_346 : Float(1, 256, 64, strides=[16384, 64, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_347 : Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_369 : Float(1, 256, 64, strides=[16384, 64, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_370 : Float(1, 256, 64, strides=[16384, 64, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::LSTM_371 : Float(1, 512, strides=[512, 1], requires_grad=0, device=cpu)):\n",
      "  %/lstm/Transpose_output_0 : Float(8, 64, 40, strides=[2560, 40, 1], device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/lstm/Transpose\"](%input), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::LSTM_17 : Tensor? = prim::Constant(), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/lstm/Constant\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_1_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/lstm/Constant_1\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/lstm/Shape\"](%/lstm/Transpose_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_2\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Gather_output_0 : Long(device=cpu) = onnx::Gather[onnx_name=\"/lstm/Gather\"](%/lstm/Shape_output_0, %/lstm/Constant_2_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Unsqueeze_88 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %onnx::Concat_89 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%/lstm/Gather_output_0, %onnx::Unsqueeze_88)\n",
      "  %/lstm/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={64}, onnx_name=\"/lstm/Constant_3\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Concat_326 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %/lstm/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/lstm/Concat\"](%onnx::Concat_326, %onnx::Concat_89, %/lstm/Constant_3_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Expand_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Expand[onnx_name=\"/lstm/Expand\"](%/lstm/Constant_output_0, %/lstm/Concat_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/lstm/Shape_1\"](%/lstm/Transpose_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_4_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_4\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[onnx_name=\"/lstm/Gather_1\"](%/lstm/Shape_1_output_0, %/lstm/Constant_4_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Unsqueeze_99 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %onnx::Concat_100 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%/lstm/Gather_1_output_0, %onnx::Unsqueeze_99)\n",
      "  %/lstm/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={64}, onnx_name=\"/lstm/Constant_5\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Concat_327 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %/lstm/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/lstm/Concat_1\"](%onnx::Concat_327, %onnx::Concat_100, %/lstm/Constant_5_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Expand_1_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Expand[onnx_name=\"/lstm/Expand_1\"](%/lstm/Constant_1_output_0, %/lstm/Concat_1_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/LSTM_output_0 : Float(8, 1, 64, 64, strides=[4096, 4096, 64, 1], device=cpu), %/lstm/LSTM_output_1 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu), %/lstm/LSTM_output_2 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::LSTM[hidden_size=64, onnx_name=\"/lstm/LSTM\"](%/lstm/Transpose_output_0, %onnx::LSTM_321, %onnx::LSTM_322, %onnx::LSTM_323, %onnx::LSTM_17, %/lstm/Expand_output_0, %/lstm/Expand_1_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_6\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Squeeze_output_0 : Float(8, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Squeeze[onnx_name=\"/lstm/Squeeze\"](%/lstm/LSTM_output_0, %/lstm/Constant_6_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_7_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/lstm/Constant_7\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_8_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/lstm/Constant_8\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/lstm/Shape_2\"](%/lstm/Squeeze_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_9_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_9\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[onnx_name=\"/lstm/Gather_2\"](%/lstm/Shape_2_output_0, %/lstm/Constant_9_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Unsqueeze_182 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %onnx::Concat_183 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%/lstm/Gather_2_output_0, %onnx::Unsqueeze_182)\n",
      "  %/lstm/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={64}, onnx_name=\"/lstm/Constant_10\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Concat_350 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %/lstm/Concat_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/lstm/Concat_2\"](%onnx::Concat_350, %onnx::Concat_183, %/lstm/Constant_10_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Expand_2_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Expand[onnx_name=\"/lstm/Expand_2\"](%/lstm/Constant_7_output_0, %/lstm/Concat_2_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/lstm/Shape_3\"](%/lstm/Squeeze_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_11\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[onnx_name=\"/lstm/Gather_3\"](%/lstm/Shape_3_output_0, %/lstm/Constant_11_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Unsqueeze_193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %onnx::Concat_194 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%/lstm/Gather_3_output_0, %onnx::Unsqueeze_193)\n",
      "  %/lstm/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={64}, onnx_name=\"/lstm/Constant_12\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Concat_351 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %/lstm/Concat_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/lstm/Concat_3\"](%onnx::Concat_351, %onnx::Concat_194, %/lstm/Constant_12_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Expand_3_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Expand[onnx_name=\"/lstm/Expand_3\"](%/lstm/Constant_8_output_0, %/lstm/Concat_3_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/LSTM_1_output_0 : Float(8, 1, 64, 64, strides=[4096, 4096, 64, 1], device=cpu), %/lstm/LSTM_1_output_1 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu), %/lstm/LSTM_1_output_2 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::LSTM[hidden_size=64, onnx_name=\"/lstm/LSTM_1\"](%/lstm/Squeeze_output_0, %onnx::LSTM_345, %onnx::LSTM_346, %onnx::LSTM_347, %onnx::LSTM_17, %/lstm/Expand_2_output_0, %/lstm/Expand_3_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_13\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Squeeze_1_output_0 : Float(8, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Squeeze[onnx_name=\"/lstm/Squeeze_1\"](%/lstm/LSTM_1_output_0, %/lstm/Constant_13_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_14_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/lstm/Constant_14\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_15_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>, onnx_name=\"/lstm/Constant_15\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/lstm/Shape_4\"](%/lstm/Squeeze_1_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_16_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_16\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Gather_4_output_0 : Long(device=cpu) = onnx::Gather[onnx_name=\"/lstm/Gather_4\"](%/lstm/Shape_4_output_0, %/lstm/Constant_16_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Unsqueeze_276 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %onnx::Concat_277 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%/lstm/Gather_4_output_0, %onnx::Unsqueeze_276)\n",
      "  %/lstm/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={64}, onnx_name=\"/lstm/Constant_17\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Concat_374 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %/lstm/Concat_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/lstm/Concat_4\"](%onnx::Concat_374, %onnx::Concat_277, %/lstm/Constant_17_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Expand_4_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Expand[onnx_name=\"/lstm/Expand_4\"](%/lstm/Constant_14_output_0, %/lstm/Concat_4_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Shape_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/lstm/Shape_5\"](%/lstm/Squeeze_1_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_18_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_18\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[onnx_name=\"/lstm/Gather_5\"](%/lstm/Shape_5_output_0, %/lstm/Constant_18_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Unsqueeze_287 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %onnx::Concat_288 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%/lstm/Gather_5_output_0, %onnx::Unsqueeze_287)\n",
      "  %/lstm/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={64}, onnx_name=\"/lstm/Constant_19\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %onnx::Concat_375 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %/lstm/Concat_5_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name=\"/lstm/Concat_5\"](%onnx::Concat_375, %onnx::Concat_288, %/lstm/Constant_19_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Expand_5_output_0 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Expand[onnx_name=\"/lstm/Expand_5\"](%/lstm/Constant_15_output_0, %/lstm/Concat_5_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/LSTM_2_output_0 : Float(8, 1, 64, 64, strides=[4096, 4096, 64, 1], device=cpu), %/lstm/LSTM_2_output_1 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu), %/lstm/LSTM_2_output_2 : Float(1, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::LSTM[hidden_size=64, onnx_name=\"/lstm/LSTM_2\"](%/lstm/Squeeze_1_output_0, %onnx::LSTM_369, %onnx::LSTM_370, %onnx::LSTM_371, %onnx::LSTM_17, %/lstm/Expand_4_output_0, %/lstm/Expand_5_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name=\"/lstm/Constant_20\"](), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Squeeze_2_output_0 : Float(8, 64, 64, strides=[4096, 64, 1], device=cpu) = onnx::Squeeze[onnx_name=\"/lstm/Squeeze_2\"](%/lstm/LSTM_2_output_0, %/lstm/Constant_20_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/lstm/Transpose_1_output_0 : Float(64, 8, 64, strides=[64, 4096, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[1, 0, 2], onnx_name=\"/lstm/Transpose_1\"](%/lstm/Squeeze_2_output_0), scope: __main__.LSTMModel::/torch.nn.modules.rnn.LSTM::lstm # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878:0\n",
      "  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant\"](), scope: __main__.LSTMModel::\n",
      "  %/Gather_output_0 : Float(64, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=1, onnx_name=\"/Gather\"](%/lstm/Transpose_1_output_0, %/Constant_output_0), scope: __main__.LSTMModel:: # /tmp/ipykernel_37149/3919073403.py:29:0\n",
      "  %output : Float(64, 1, strides=[1, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc/Gemm\"](%/Gather_output_0, %fc.weight, %fc.bias), scope: __main__.LSTMModel::/torch.nn.modules.linear.Linear::fc # /mnt/mechanical/softwares/anaconda3/envs/speaker-recg/lib/python3.12/site-packages/torch/nn/modules/linear.py:116:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# export as onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "onnx_path = \"models/final_lstm_64_class_dynamic.onnx\"\n",
    "# model = LSTMModel()\n",
    "model = torch.load(\"models/final_e800_full_model_for_64.pth\")\n",
    "model = model.to(\"cpu\")\n",
    "# 虚拟输入张量，作为导出时的参数，其维度要跟输入维度相对应\n",
    "dummy_input = torch.randn(1, 8, 40).to(\"cpu\")  # 使用单个样本进行导出\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    f=onnx_path,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    # 使用动态batch\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36.]\n",
      " [36.]\n",
      " [46.]\n",
      " ...\n",
      " [56.]\n",
      " [31.]\n",
      " [54.]]\n",
      "[[41.]\n",
      " [36.]\n",
      " [46.]\n",
      " ...\n",
      " [56.]\n",
      " [31.]\n",
      " [54.]]\n",
      "for e = 1000 : acc = 0.9808517156862745, f1 = 0.980723155708039\n"
     ]
    }
   ],
   "source": [
    "# eval with onnx and batchsize=64 and without torch\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(onnx_path)\n",
    "\n",
    "all_y_true = np.zeros((0, 1))\n",
    "all_y_pred = np.zeros((0, 1))\n",
    "\n",
    "for inputs, y_true in val_loader:\n",
    "    inputs, y_true = (\n",
    "        inputs.to(\"cpu\").detach().numpy(),\n",
    "        y_true.to(\"cpu\").detach().numpy(),\n",
    "    )\n",
    "    # 跳过不符合要求的 batch\n",
    "    if inputs.shape[0] != 64:\n",
    "        continue\n",
    "    # 进行推理\n",
    "    y_pred = ort_session.run(None, {\"input\": inputs})[0]\n",
    "\n",
    "    y_pred = np.round(y_pred)\n",
    "    y_true = np.round(y_true)\n",
    "\n",
    "    all_y_true = np.concatenate([all_y_true, y_true])\n",
    "    all_y_pred = np.concatenate([all_y_pred, y_pred])\n",
    "\n",
    "print(all_y_pred)\n",
    "print(all_y_true)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "\n",
    "# 计算 F1 分数\n",
    "f1 = f1_score(all_y_true, all_y_pred, average=\"macro\")\n",
    "print(f\"for e = {e} : acc = {accuracy}, f1 = {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
